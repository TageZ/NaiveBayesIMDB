{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Homework2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tagez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# pip install nltk\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import otter\n",
    "\n",
    "grader = otter.Notebook()\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_data(review):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    review = review.lower()\n",
    "\n",
    "    review = emoji_pattern.sub(r'', review)   \n",
    "\n",
    "    #Remove contractions\n",
    "    review=re.sub(\"isn't\", \"is not\", review)\n",
    "    review=re.sub(\"he's\", \"he is\", review)\n",
    "    review=re.sub(\"what's\", \"what is\", review)\n",
    "    review=re.sub(\"it's\", \"it is\", review)\n",
    "    review=re.sub(\"couldn't\", \"could not\", review)\n",
    "    review=re.sub(\"wouldn't\", \"would not\", review)\n",
    "    review=re.sub(\"can't\", \"cannot\", review)\n",
    "    review=re.sub(\"we're\", \"we are\", review)\n",
    "    review=re.sub(\"aren't\", \"are not\", review)\n",
    "    review=re.sub(\"i'm\", \"i am\", review)\n",
    "    review=re.sub(\"you're\", \"you are\", review)\n",
    "    review=re.sub(\"she's\", \"she is\", review)\n",
    "    review=re.sub(\"wasn't\", \"was not\", review)\n",
    "    review=re.sub(\"they're\", \"they are\", review)\n",
    "    review=re.sub(\"hasn't\", \"has not\", review)\n",
    "    review=re.sub(\"that's\", \"that is\", review)\n",
    "    review=re.sub(\"here's\", \"here is\", review)\n",
    "    review=re.sub(\"who's\", \"who is\", review)\n",
    "    review=re.sub(\"there's\", \"there is\", review)\n",
    "    review=re.sub(\"weren't\", \"were not\", review)\n",
    "    review=re.sub(\"haven't\", \"have not\", review)\n",
    "    review=re.sub(\"don't\", \"do not\", review)\n",
    "    review=re.sub(\"hadn't\", \"had not\", review)\n",
    "    review=re.sub(\"won't\", \"will not\", review)\n",
    "    review=re.sub(\"did't\", \"did not\", review)\n",
    "    review=re.sub(\"doesn't\", \"does not\", review)\n",
    "    review=re.sub(\"shouldn't\", \"should not\", review)\n",
    "\n",
    "    #Remove links\n",
    "    review = re.sub('https?://\\S+|www\\.\\S+', '', review)\n",
    "\n",
    "    #Remove non alphabetic characters\n",
    "    review = re.sub(r'\\n', ' ', review)\n",
    "    review = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in and clean data\n",
    "data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "cleaned_data = data['review'].apply(clean_data)\n",
    "\n",
    "cleaned_data = pd.DataFrame(cleaned_data)\n",
    "cleaned_data['sentiment'] = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "# this will take a long time to run, likely at least 10 minutes.\n",
    "cleaned_data['no_sw'] = cleaned_data['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find value counts of all words in all data points\n",
    "counter = Counter()\n",
    "for text in cleaned_data[\"no_sw\"].values:\n",
    "    for word in text.split():\n",
    "        counter[word] += 1\n",
    "\n",
    "# creates a set of the 10 most common words amongst all reviews\n",
    "FREQWORDS = set([w for (w, wc) in counter.most_common(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_freqwords(text, freqwords):\n",
    "    '''Given a review that has been cleaned, returns the review without the most frequently appearing words'''\n",
    "    return ' '.join([word for word in text.split() if word not in (freqwords)])\n",
    "        \n",
    "# remove frequent words that do not add value to the model\n",
    "cleaned_data[\"no_sw\"] = cleaned_data[\"no_sw\"].apply(lambda text: remove_freqwords(text, FREQWORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace the sentiment with binary 0 or 1, prepare for model\n",
    "tokenized_data = cleaned_data.drop(columns=['review'])\n",
    "tokenized_data.columns = ['sentiment', 'review']\n",
    "\n",
    "#convert the sentiment values to a binary 0 or 1\n",
    "tokenized_data['sentiment'] = tokenized_data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "#complete data preprocessing by changing the review format from a string of words to a list of strings containing individual words\n",
    "tokenized_data['review'] = tokenized_data['review'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Part 2: Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NaiveBayesModel:\n",
    "    '''Class representing the implementation of the Naive Bayes model'''\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.occurrence_table = {}\n",
    "        self.probability_table = {}\n",
    "        self.labels = []\n",
    "\n",
    "    def train_model(self, data, labels):\n",
    "        '''Runs the training process for the model, building the occurrence table and probability table'''\n",
    "\n",
    "        self.labels = list(set(labels))\n",
    "        self.build_occurrence_table(data, labels)\n",
    "        self.build_probability_table()\n",
    "\n",
    "        pass\n",
    "\n",
    "    def build_occurrence_table(self, data, labels):\n",
    "        '''Private function to create the occurrence table given the training data and labels'''\n",
    "\n",
    "        # creates a nested dictionary table of frequencies based on the training data.\n",
    "        # example format for the word 'word': {'word': {0: 3, 1: 15}}\n",
    "\n",
    "        for review, sentiment in zip(data, labels):\n",
    "            for word in review:\n",
    "                if word not in self.occurrence_table:\n",
    "                    self.occurrence_table[word] = {0: 0, 1: 0}\n",
    "                \n",
    "                self.occurrence_table[word][sentiment] += 1\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def build_probability_table(self):\n",
    "        '''Private function to create the probability table based on the occurrence table'''\n",
    "\n",
    "        # generates a table of probabilities based on the frequencies recorded in the occurrence table\n",
    "        # example format for the word 'word': {'word': {0: 0.1667, 1: 0.8333}}\n",
    "\n",
    "        for word, sentiment_counts in self.occurrence_table.items():\n",
    "            total_occurrences = sum(sentiment_counts.values())\n",
    "\n",
    "            probabilities = {}\n",
    "            for sentiment, count in sentiment_counts.items():\n",
    "                probabilities[sentiment] = count / total_occurrences\n",
    "\n",
    "            self.probability_table[word] = probabilities\n",
    "\n",
    "        pass\n",
    "\n",
    "    def predict(self, variables):\n",
    "        '''Takes a set of variables, and predicts the class they should belong to'''\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for variable in variables:\n",
    "            neg_probability = self.naive_bayes(0, variable)\n",
    "            pos_probability = self.naive_bayes(1, variable)\n",
    "\n",
    "            if (neg_probability == pos_probability):\n",
    "                predicted_label = random.choice([0, 1])\n",
    "            else:\n",
    "                predicted_label = 0 if neg_probability > pos_probability else 1\n",
    "\n",
    "            predictions.append(predicted_label)\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "    def naive_bayes(self, label, variable):\n",
    "        probability = self.labels.count(label) / len(self.labels)\n",
    "\n",
    "        for word in variable:\n",
    "            if word in self.probability_table:\n",
    "                probability *= self.probability_table[word][label]\n",
    "\n",
    "        return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# perform a train/test split on the data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X\u001b[38;5;241m=\u001b[39m\u001b[43mtokenized_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m y\u001b[38;5;241m=\u001b[39mtokenized_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenized_data' is not defined"
     ]
    }
   ],
   "source": [
    "# perform a train/test split on the data\n",
    "X=tokenized_data['review']\n",
    "y=tokenized_data['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=30)\n",
    "\n",
    "# train and predict using the Naive Bayes model implementation\n",
    "nb_model = NaiveBayesModel()\n",
    "nb_model.train_model(X_train, y_train)\n",
    "pred = nb_model.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m confusion_matrix \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(\u001b[43my_test\u001b[49m, pred)\n\u001b[0;32m     10\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_test, pred)\n\u001b[0;32m     11\u001b[0m precision \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mprecision_score(y_test, pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "#TODO - Create and display confusion matrices and evaluation metrics to prove the performance of your model.\n",
    "# required: accuracy, recall, f-score\n",
    "\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, pred)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, pred)\n",
    "precision = metrics.precision_score(y_test, pred)\n",
    "recall = metrics.recall_score(y_test, pred)\n",
    "f_score = metrics.f1_score(y_test, pred)\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F-Score: \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "naivebayes",
   "tests": {
    "p1": {
     "name": "p1",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
